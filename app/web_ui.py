import streamlit as st
import sys
import os
from pathlib import Path
import json

# Add project root to path
project_root = Path(__file__).resolve().parents[1]
sys.path.append(str(project_root))

from app.services.knowledge_base import KnowledgeBase
from app.services.embeddings import EmbeddingService
from app.services.llm import LLMService
from app.core.config import settings

st.set_page_config(page_title="å¤šæ¨¡æ€åŒ»ç–—å’¨è¯¢åŠ©æ‰‹", page_icon="ğŸ¥", layout="wide")

@st.cache_resource
def load_services():
    with st.spinner("æ­£åœ¨åŠ è½½æ¨¡å‹å’ŒæœåŠ¡..."):
        embedding_service = EmbeddingService("openai/clip-vit-base-patch32")
        kb = KnowledgeBase()
        llm = LLMService()
        return embedding_service, kb, llm

try:
    embedding_service, kb, llm = load_services()
except Exception as e:
    st.error(f"æœåŠ¡åŠ è½½å¤±è´¥: {e}")
    st.stop()

st.title("ğŸ¥ å¤šæ¨¡æ€åŒ»ç–—å’¨è¯¢åŠ©æ‰‹")
st.markdown("---")

if "messages" not in st.session_state:
    st.session_state.messages = []

# Sidebar for settings or info
with st.sidebar:
    st.header("ç³»ç»ŸçŠ¶æ€")
    st.success("æœåŠ¡å·²è¿æ¥")
    st.info("æœ¬ç³»ç»Ÿæ”¯æŒæ–‡æœ¬å’Œå›¾åƒå¤šæ¨¡æ€æ£€ç´¢ã€‚")
    if st.button("æ¸…ç©ºå¯¹è¯"):
        st.session_state.messages = []
        st.rerun()

# Display chat history
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if "images" in message:
            cols = st.columns(min(len(message["images"]), 3))
            for idx, img_path in enumerate(message["images"]):
                if idx < 3: # Limit display in history to avoid clutter
                    with cols[idx]:
                        if os.path.exists(img_path):
                            st.image(img_path, caption="å‚è€ƒå½±åƒ", use_column_width=True)

prompt = st.chat_input("è¯·æè¿°æ‚¨çš„ç—‡çŠ¶æˆ–ä¸Šä¼ åŒ»å­¦å½±åƒ...")

if prompt:
    # Add user message
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Process
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        with st.spinner("æ­£åœ¨åˆ†æåŒ»ç–—æ•°æ®..."):
            try:
                # 1. Embed
                query_vector = embedding_service.embed_query(prompt)[0]
                
                # 2. Text Search (Hybrid)
                text_results = kb.hybrid_search(prompt, query_vector, top_k=3, rerank=True)
                
                # 3. Image Search (Text-to-Image)
                image_results = kb.search_images(query_vector, top_k=3)
                
                # Logic Check for Department
                top_dept = None
                
                # Check top result's department
                if text_results and text_results[0]:
                    top_hit = text_results[0][0]
                    entity = top_hit.get("entity", {})
                    dept = entity.get("department", "")
                    # Filter out invalid departments
                    if dept and str(dept).lower() not in ["unknown", "nan", "none", ""]:
                        top_dept = dept
                
                display_images = []
                response_content = ""
                
                if top_dept:
                    # Case 1: Department Found -> Recommend it
                    response_content += f"### âœ… å»ºè®®å°±è¯Šç§‘å®¤ï¼š{top_dept}\n\n"
                    response_content += "æ ¹æ®æ‚¨çš„æè¿°ï¼ŒåŒ¹é…åˆ°ç›¸å…³ç—…ä¾‹å±äºè¯¥ç§‘å®¤ã€‚å»ºè®®æ‚¨å‰å¾€è¯¥ç§‘å®¤è¿›è¡Œè¯¦ç»†æ£€æŸ¥åŠå’¨è¯¢ã€‚\n\n"
                    
                    # LLM Analysis for more details
                    context = ""
                    for hits in text_results:
                        for hit in hits:
                            entity = hit.get('entity', {})
                            context += f"ç—…ä¾‹: {entity.get('text', '')}\nç§‘å®¤: {entity.get('department', '')}\n\n"
                    
                    suggestion = llm.get_consultation_suggestion(prompt, context)
                    response_content += f"#### ğŸ“‹ æ™ºèƒ½åˆ†æï¼š\n{suggestion}"
                    
                else:
                    # Case 2: No Department -> Show Images + Text + Suggestion
                    response_content += "æœªåŒ¹é…åˆ°æ˜ç¡®çš„å»ºè®®ç§‘å®¤ã€‚ä»¥ä¸‹æ˜¯ä¸ºæ‚¨æ‰¾åˆ°çš„ç›¸å…³å‚è€ƒèµ„æ–™å’Œå»ºè®®ï¼š\n\n"
                    
                    # Collect Images
                    if image_results and image_results[0]:
                        for hit in image_results[0]:
                            entity = hit.get('entity', {})
                            img_path = entity.get('image_path')
                            if img_path and os.path.exists(img_path):
                                if img_path not in display_images:
                                    display_images.append(img_path)
                    
                    # Context for LLM
                    context = "æ–‡æœ¬èµ„æ–™:\n"
                    if text_results and text_results[0]:
                        for hit in text_results[0]:
                            context += f"- {hit['entity'].get('text', '')}\n"
                    
                    context += "\nå½±åƒèµ„æ–™:\n"
                    if image_results and image_results[0]:
                        for hit in image_results[0]:
                            caption = hit['entity'].get('text', '')
                            context += f"- {caption}\n"

                    # LLM Suggestion
                    suggestion = llm.get_consultation_suggestion(prompt, context)
                    response_content += f"#### ğŸ©º è¯Šç–—å»ºè®®ï¼š\n{suggestion}"
                
                # Display Response
                message_placeholder.markdown(response_content)
                
                # Display Images (if any, primarily for Case 2 but good to show if available)
                if display_images:
                    st.write("#### ğŸ–¼ï¸ å‚è€ƒå½±åƒï¼š")
                    cols = st.columns(len(display_images))
                    for idx, img_path in enumerate(display_images):
                        with cols[idx % 3]:
                            st.image(img_path, caption="æ£€ç´¢ç»“æœ", use_column_width=True)
                
                # Save to history
                msg_entry = {"role": "assistant", "content": response_content}
                if display_images:
                    msg_entry["images"] = display_images
                st.session_state.messages.append(msg_entry)
                
            except Exception as e:
                st.error(f"å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {e}")
